{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bar charts for hypernym relation with 4 models PRECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\is_a\\hypernym_sents_masked_first_20.txt\n",
      "is_a\n",
      "['P@1: 0.21725239616613418\\n', 'P@2: 0.19968051118210864\\n', 'P@5: 0.15463258785942502\\n', 'P@10: 0.11246006389776363\\n']\n",
      "P@1 0.21725239616613418\n",
      "P@2 0.19968051118210864\n",
      "P@5 0.15463258785942502\n",
      "P@10 0.11246006389776363\n",
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\is_a\\hypernym_sents_masked_second_20.txt\n",
      "is_a\n",
      "['P@1: 0.05687203791469194\\n', 'P@2: 0.052132701421800945\\n', 'P@5: 0.03791469194312798\\n', 'P@10: 0.02464454976303318\\n']\n",
      "P@1 0.05687203791469194\n",
      "P@2 0.052132701421800945\n",
      "P@5 0.03791469194312798\n",
      "P@10 0.02464454976303318\n",
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\specific_term\\hypernym_sents_masked_first_20.txt\n",
      "specific_term\n",
      "['P@1: 0.2268370607028754\\n', 'P@2: 0.21725239616613418\\n', 'P@5: 0.16549520766773165\\n', 'P@10: 0.12396166134185314\\n']\n",
      "P@1 0.2268370607028754\n",
      "P@2 0.21725239616613418\n",
      "P@5 0.16549520766773165\n",
      "P@10 0.12396166134185314\n",
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\specific_term\\hypernym_sents_masked_second_20.txt\n",
      "specific_term\n",
      "['P@1: 0.02843601895734597\\n', 'P@2: 0.030805687203791468\\n', 'P@5: 0.03222748815165878\\n', 'P@10: 0.024644549763033177\\n']\n",
      "P@1 0.02843601895734597\n",
      "P@2 0.030805687203791468\n",
      "P@5 0.03222748815165878\n",
      "P@10 0.024644549763033177\n",
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\such_as\\hypernym_sents_masked_first_20.txt\n",
      "such_as\n",
      "['P@1: 0.10223642172523961\\n', 'P@2: 0.08626198083067092\\n', 'P@5: 0.09201277955271554\\n', 'P@10: 0.07859424920127807\\n']\n",
      "P@1 0.10223642172523961\n",
      "P@2 0.08626198083067092\n",
      "P@5 0.09201277955271554\n",
      "P@10 0.07859424920127807\n",
      "File: /Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/bert/wn\\such_as\\hypernym_sents_masked_second_20.txt\n",
      "such_as\n",
      "['P@1: 0.14218009478672985\\n', 'P@2: 0.12322274881516587\\n', 'P@5: 0.06919431279620847\\n', 'P@10: 0.04786729857819898\\n']\n",
      "P@1 0.14218009478672985\n",
      "P@2 0.12322274881516587\n",
      "P@5 0.06919431279620847\n",
      "P@10 0.04786729857819898\n"
     ]
    }
   ],
   "source": [
    "# Load the results\n",
    "\n",
    "model = \"bert\"\n",
    "kb = \"wn\"\n",
    "main_folder = f'/Users/128525/Desktop/Uni/SemGPT/it/unito/evaluation/{model}/{kb}'\n",
    "precisions = []\n",
    "\n",
    "for file in glob(main_folder+'/**/*.txt'):\n",
    "    print(f'File: {file}')\n",
    "    \n",
    "    print(file.split(\"\\\\\")[-2])\n",
    "    # estrarre il tipo di test (is_a, specific_term, such_as) dal path del file\n",
    "\n",
    "    with open(file, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()[:4] # Only the first 4 lines are precision@k\n",
    "        print(lines)\n",
    "        \n",
    "        for line in lines:\n",
    "            split = line.strip().split(\": \")\n",
    "            prec_k = split[0]\n",
    "            prec_v = float(split[1])\n",
    "            print(f'{prec_k} {prec_v}')\n",
    "\n",
    "\n",
    "\n",
    "#with open('results.txt', 'r', encoding=\"utf8\") as f:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bar plot precision\n",
    "\n",
    "models = None # ci sono i modelli utilizzati (\"bert\", \"roberta\", \"phi-1.5\", \"electra\")\n",
    "precision_means = {\n",
    "    'is_a': (inserisco i valori letti),\n",
    "    'specific_term': (inserisco i valori letti),\n",
    "    'such_as': (inserisco i valori letti),\n",
    "}\n",
    "\n",
    "x = np.arange(len(models))  # the label models\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "for attribute, measurement in precision_means.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Precision@1')\n",
    "ax.set_title('Precision@1 for BERT, RoBERTa, Phi-1.5 and ELECTRA models on WordNet')\n",
    "ax.set_xticks(x + width, species)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 250)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conceptnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
